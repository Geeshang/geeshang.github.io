---
layout: post
permalink: /rcnn
title: 解读R-CNN魔改之路：从R-CNN到Mask R-CNN
comments: true
date: 2018-06-19
mathjax: true
---

从R-CNN、Fast R-CNN、Fater R-CNN到Mask R-CNN，这一路算是在深度学习时代目标检测（object detection）的里程碑式的论文，是two-stage这个分支的代表作。R-CNN怎么就越来越fater了？Mask R-CNN添加一个分支就把目标检测与实例分割（instance segmentation）联系起来了？本文将梳理R-CNN这一支的发展历程，解读其魔改之路。

## R-CNN
R-CNN大概在2013年末提出来，距离引发这一波计算机视觉、人工智能革命浪潮重磅的AlexNet论文刚发表不久。当时研究者们还在讨论AlexNet的模型知识能不能迁移到目标检测的任务中来，目标检测领域在已经处于停滞状态，依靠各种魔改DPM（deformable part model）模型，加上各种集成（ensemble）方法的操作，在PASCAL VOC数据集每年带来可怜的几个百分点的提升。

Features matter! AlexNet之所以能在ImageNet的图像分类任务中取得大幅度提升，就是因为摆脱了表征能力弱的手工设计的特征，如SIFT、HOG等，采用了深度卷积神经网络的模型来学习得到的特征。R-CNN采用CNN网络提取的特征，也是其命名的由来，Regions with CNN features。

![](../assets/images/R-CNN.png)

### 测试过程：
R-CNN测试过程的分为两个阶段：

第一阶段从原图上运行selective search 得到一些RoI（约2k个），然后把这些RoI依次送入CNN网络提取特征。第二阶段，把提取到的特征送入由1 vs all策略构成的SVM分类器，得到所属类别，同时进行bounding box regression对RoI的坐标进行修正。

### 训练过程：
分为3个步骤：

1. 微调（fine-tuning）
    
    将ImageNet训练的CNN模型，在特定数据集上（如Paccal VOC）进行微调，相当于以小一个数量级的学习率（0.001）再做一遍分类任务的训练。注意有个采样比例：RoI与任意ground truth的IoU >0.5，就算作正样本，否则是负样本，按照正负样本1：3比例进行采样。

2. 训练SVM分类器
    
3. 训练bbox回归器

### R-CNN的缺点：
1. 训练流程复杂
    - 首先需要对CNN模型进行fine tuning
    - 训练SVM分类器
    - 训练bounding box regressor

    这几个过程都是分别进行的，操作比较复杂。

2. 训练过程时间、空间代价较高

    由于需要单独训练SVM和bbox回归器，中间特征文件需要单独存储，在VOC2017只有5k的数据集上，硬盘空间需要几百个G，单GPU需要2、3天的时间。

3. 检测时间慢

    在R-CNN中，每个RoI都要单独运行一遍CNN提取特征的过程，每张图片都需要运行2000多次CNN模型，这无疑是比较缓慢的。使用VGG16作为CNN backbone 特征提取器，R-CNN在GPU上检测一张图片大约需要47s。

## Fast R-CNN

## Faster R-CNN

## Mask R-CNN

## 其他变种
### Light-Head R-CNN

## 参考文献
1. [DPM模型原始论文-Object Detection with Discriminatively Trained
Part Based Models](http://cs.brown.edu/people/pfelzens/papers/lsvm-pami.pdf)
2. [Selective Search for Object Recognition](https://ivi.fnwi.uva.nl/isis/publications/2013/UijlingsIJCV2013/UijlingsIJCV2013.pdf)