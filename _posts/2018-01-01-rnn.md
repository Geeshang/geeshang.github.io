---
layout: post
permalink: /rnn
title: RNN、LSTM、GRU网络原理与实现解析
---

(持续更新中)

## 1. RNN发展过程
传统RNN梯度弥散与长距离依赖问题
对序列数据进行建模中，存在长距离依赖(Long distance dependence)的问题，普通RNN对此难以应对

## 2. LSTM cell 原理
### BLSTM 原理
## 3. GRU cell 原理

## 4. LSTM、GRU多层网络
## 5. 实现解析
### PyTorch实现解析

### TensorFlow实现解析

## 6. LSTM对比CRF、HMM

参考文献：

[1] [Rafa Jozefowicz et al. An Empirical Exploration of Recurrent Network Architectures.](http://proceedings.mlr.press/v37/jozefowicz15.pdf)

[2] [Junyoung Chung et al. Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling.](https://arxiv.org/pdf/1412.3555.pdf)

[2] [CRF和LSTM模型在序列标注上的优劣？](https://www.zhihu.com/question/46688107)

[3] [LSTM如何来避免梯度弥散和梯度爆炸？](https://www.zhihu.com/question/34878706)